{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting FDA Approval of Small Molecule Drugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Metis Project 5 (\"Kojak\"): Capstone*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "The drug development process is a high-risk, long-term and expensive endeavor. On average, tens of thousands of drug candidates enter the drug discovery pipeline for every one becomes FDA-approved. In addition to this high attrition, this process takes 10 years and is estimated to cost $1.4 billion (1). Machine Learning could help reduce the risk, thereby lowering costs and expediting the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/funnel09.png\" alt=\"Drug Discovery Process\" width=\"800\" align=“center”/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "My data source was ChEMBL: a chemical database curated by the European Molecular Biology Laboratory. It was hosted on Google BigQuery and was also available for download as a PostgreSQL database. It contains information on over 1 million drug-like molecules in 77 tables. I decided to focus on small molecules.\n",
    "\n",
    "After cleaning and excluding any entries from the past 10 years, I was left with 432,000 entries. My dataset was highly imbalanced, as only 0.4% of these small molecules attained FDA approval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods\n",
    "\n",
    "#### *SQL*\n",
    "\n",
    "I used the Google BigQuery Python Client Library `bigquery` and the helper class `bq_helper` to query the ChEMBL database. I performed a series of SQL queries to extract data from SQL tables into pandas dataframe.\n",
    "\n",
    "#### *Feature Selection & Engineering*\n",
    "The ‘COMPOUND_PROPERTIES’ table contained chemical properties of the molecules. These were mostly numerical features and were thus an obvious choice to include. Other tables contained more categorical variables with large numbers of levels. For assays (395 levels) and targets (12,000 levels), I took their assigned parent class. For Target organisms, I created a Boolean variable: was it human or not.\n",
    "\n",
    "A given small molecule might have multiple activity entries -- in other words, it could have one or more targets and assays associated with it. I thus couldn't simply use `OneHotEncode` on these features, so I used `CountVectorize` to encode this information instead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Before encoding:\n",
    "    `'UNDEFINED,NON-MOLECULAR,PROTEIN'`\n",
    "\n",
    "> After CountVectorize:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also tallied the number of activities, assays, targets, and target organisms by molecule. The number of targets and activities were highly correlated, so I merged these into one feature by taking their average. These were also correlated with the number of assays, so I computed the ratio of this average with the number of assays. \n",
    "\n",
    "A list of final features is given in my GitHub repository."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Data Processing*\n",
    "\n",
    "Before sending my data into classifier algorithms, I had to preprocess it as follows: \n",
    "-\tImpute missing values\n",
    "-\tScale numerical variables (for Logistic Regression) \n",
    "-\tCountVectorize the categorical variables for which entries can take on >1 level\n",
    "-\tOne-Hot-Encode the other categorical variables\n",
    "-\tengineer features\n",
    "\n",
    "Because of the diversity of my feature datatypes, I decided to make use of scikit-learn’s Pipelines, using the ColumnTransformer, FunctionTransformer, and FeatureUnion functions. I also created custom TransformerMixin Classes to handle some of the preprocessing tasks.\n",
    "\n",
    "#### *Modeling*\n",
    "I evaluated Logistic Regression, Random Forest, Bagged Decision Trees, and “vanilla” Gradient Boosting (Decision Trees) algorithms. These were all out-performed by CatBoost, an algorithm based on gradient-boosted decision trees, which is especially fast and adept at handling categorical variables. I also investigated various methods of over- and under-sampling to address the imbalance in my dataset including SMOTE, ADASYN, Random Undersampling, Edited Nearest Neighbors, Near Miss versions 1 & 3, SMOTE-EEN, SMOTE-Tomek, and assigning class weights. None improved the performance of my models.\n",
    "\n",
    "#### *Tuning*\n",
    "I then tuned the hyperparameters of CatBoost. First, I tuned the number of iterations (number of estimators), using F1 score to check for overfitting. (I had to set the p-value low (10-10) to permit the model to fit appropriately. Larger p-values stopped the fitting early and resulted in underfitting.) At a depth of 6, ~175 iterations were optimal. Then I tuned other parameters using BayesSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
